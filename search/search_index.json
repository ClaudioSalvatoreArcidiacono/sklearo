{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homepage","text":""},{"location":"#sklearo","title":"Sklearo","text":"<p>A versatile Python package featuring scikit-learn like transformers for feature preprocessing, compatible with all kind of DataFrames thanks to narwhals.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install the package, use pip:</p> <pre><code>pip install sklearo\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Here's a basic example of how to use the package with the <code>WOEEncoder</code>:</p> <pre><code>import pandas as pd\nfrom sklearo.encoding import WOEEncoder\n\n\ndata = {\n    \"category\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n    \"target\": [1, 0, 0, 1, 1, 0, 1, 1, 0],\n}\ndf = pd.DataFrame(data)\nencoder = WOEEncoder()\nencoder.fit(df[[\"category\"]], df[\"target\"])\nencoded = encoder.transform(df[[\"category\"]])\nprint(encoded)\n   category\n0 -0.916291\n1 -0.916291\n2 -0.916291\n3  0.470004\n4  0.470004\n5  0.470004\n6  0.470004\n7  0.470004\n8  0.470004\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>\u222b Easy Integration: built on top of narwhals, meaning it can work with any kind of dataframe supported by narwhals like pandas, polars and much more!</li> <li>\ud83c\udf38 Scikit-learn Compatibility: Designed to work with scikit-learn pipelines.</li> <li>\u2705 tested against pandas and Polars dataframes.</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! Please check the development guides for more details.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p>"},{"location":"#contact","title":"Contact","text":"<p>For any questions or suggestions, please open an issue on GitHub.</p>"},{"location":"#why-sklearo","title":"Why <code>sklearo</code>?","text":"<p>The name <code>sklearo</code> is a combination of <code>sklearn</code> and omni (<code>o</code>), which means all. This package is designed to work with all kinds of dataframes, hence the name <code>sklearo</code>.</p>"},{"location":"API/encoding/TargetEncoder/","title":"TargetEncoder","text":""},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder","title":"<code>sklearo.encoding.TargetEncoder(columns=(nw.Categorical, nw.String), unseen='raise', fill_value_unseen='mean', missing_values='encode', underrepresented_categories='raise', fill_values_underrepresented='mean', target_type='auto', smooth='auto', cv=5)</code>","text":"<p>Target Encoder for categorical features.</p> <p>This class provides functionality to encode categorical features using the Target Encoding technique. Target Encoding replaces each category with the mean of the target variable for that category. This method is particularly useful for handling categorical variables in machine learning models, especially when the number of categories is large.</p> <p>The mean target per category is blended with the overall mean target using a smoothing parameter. The smoothing parameter is calculated as explained here.</p> Notes <p>Parameters:</p> <ul> <li> <code>columns</code>               (<code>(str, list[str], list[DTypes])</code>, default:                   <code>(Categorical, String)</code> )           \u2013            <p>List of columns to encode.</p> <ul> <li>If a list of strings is passed, it is treated as a list of column names to encode.</li> <li>If a single string is passed instead, it is treated as a regular expression pattern to   match column names.</li> <li>If a list of   <code>narwhals.typing.DTypes</code>   is passed, it will select all columns matching the specified dtype.</li> </ul> </li> <li> <code>unseen</code>               (<code>str</code>, default:                   <code>'raise'</code> )           \u2013            <p>Strategy to handle categories that appear during the <code>transform</code> step but were never encountered in the <code>fit</code> step.</p> <ul> <li>If <code>'raise'</code>, an error is raised when unseen categories are found.</li> <li>If <code>'ignore'</code>, the unseen categories are encoded with the fill_value_unseen.</li> </ul> </li> <li> <code>fill_value_unseen</code>               (<code>(int, float, None | Literal['mean'])</code>, default:                   <code>'mean'</code> )           \u2013            <p>Fill value to use for unseen categories. Defaults to <code>\"mean\"</code>, which will use the mean of the target variable.</p> </li> <li> <code>missing_values</code>               (<code>str</code>, default:                   <code>'encode'</code> )           \u2013            <p>Strategy to handle missing values.</p> <ul> <li>If <code>'encode'</code>, missing values are initially replaced with a specified fill value and   the mean is computed as if it were a regular category.</li> <li>If <code>'ignore'</code>, missing values are left as is.</li> <li>If <code>'raise'</code>, an error is raised when missing values are found.</li> </ul> </li> <li> <code>underrepresented_categories</code>               (<code>str</code>, default:                   <code>'raise'</code> )           \u2013            <p>Strategy to handle categories that are underrepresented in the training data.</p> <ul> <li>If <code>'raise'</code>, an error is raised when underrepresented categories are found.</li> <li>If <code>'fill'</code>, underrepresented categories are filled with a specified fill value.</li> </ul> </li> <li> <code>fill_values_underrepresented</code>               (<code>(float, None | Literal['mean'])</code>, default:                   <code>'mean'</code> )           \u2013            <p>Fill value to use for underrepresented categories. Defaults to <code>\"mean\"</code>, which will use the mean of the target variable.</p> </li> <li> <code>target_type</code>               (<code>str</code>, default:                   <code>'auto'</code> )           \u2013            <p>Type of the target variable.</p> <ul> <li>If <code>'auto'</code>, the type is inferred from the target variable using     <code>infer_target_type</code>.</li> <li>If <code>'binary'</code>, the target variable is binary.</li> <li>If <code>'multiclass'</code>, the target variable is multiclass.</li> <li>If <code>'continuous'</code>, the target variable is continuous.</li> </ul> </li> <li> <code>smooth</code>               (<code>(float, Literal['auto'])</code>, default:                   <code>'auto'</code> )           \u2013            <p>Smoothing parameter to avoid overfitting. If <code>'auto'</code>, the smoothing parameter is calculated based on the variance of the target variable.</p> </li> <li> <code>cv</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Number of cross-validation folds to use for calculating the target encoding.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>columns_</code>               (<code>list[str]</code>)           \u2013            <p>List of columns to be encoded, learned during fit.</p> </li> <li> <code>encoding_map_</code>               (<code>dict[str, float]</code>)           \u2013            <p>Mapping of categories to their mean target values, learned during fit.</p> </li> </ul> <p>Examples:</p> <pre><code>import pandas as pd\nfrom sklearo.encoding import TargetEncoder\ndata = {\n    \"category\": [\"A\", \"A\", \"B\", \"B\", \"C\", \"C\"],\n    \"target\": [1, 0, 1, 0, 1, 0],\n}\ndf = pd.DataFrame(data)\nencoder = TargetEncoder()\nencoder.fit(df[[\"category\"]], df[\"target\"])\nencoded = encoder.transform(df[[\"category\"]])\nprint(encoded)\ncategory\n0 0.5\n1 0.5\n2 0.5\n3 0.5\n4 0.5\n5 0.5\n</code></pre> <p>Class constructor for TargetEncoder.</p>"},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder--cross-fitting","title":"Cross-fitting \ud83c\udfcb\ufe0f\u200d\u2642\ufe0f","text":"<p>This implementation uses an internal cross-fitting strategy to calculate the mean target values for the <code>fit_transform</code> method. This means that calling <code>.fit(X, y).transform(X)</code> will not return the same result as calling <code>.fit_transform(X, y)</code>. When calling <code>.fit_transform(X, y)</code>, the dataset is initially split into k folds (configurable via the <code>cv</code> parameter) then for each fold the mean target values are calculated using the data from all other folds. Finally, the transformer is fitted on the entire dataset. This is done to prevent leakage of the target information into the training data. This idea has been taken from scikit-learn's implementation of TargetEncoder. The reader is encouraged to learn more about cross-fitting on the scikit-learn documentation.</p>"},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder.__sklearn_clone__","title":"<code>__sklearn_clone__()</code>","text":"<p>Clone the transformer.</p>"},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder.check_target_type","title":"<code>check_target_type(y)</code>","text":"<p>Check the type of the target variable.</p>"},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder.fit","title":"<code>fit(X, y)</code>","text":"<p>Fit the encoder.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>The input data.</p> </li> <li> <code>y</code>               (<code>Series</code>)           \u2013            <p>The target variable.</p> </li> </ul>"},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder.fit_transform","title":"<code>fit_transform(X, y)</code>","text":"<p>Fit the encoder and transform the dataframe using cross-fitting.</p> Notes <p>Due to the cross fitting nature of target encoding, the <code>fit_transform</code> method is NOT equivalent to calling <code>fit</code> followed by <code>transform</code>. Please refer to the note on cross fitting.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>The input data.</p> </li> <li> <code>y</code>               (<code>Series</code>)           \u2013            <p>The target variable.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseTargetEncoder</code> (              <code>BaseTargetEncoder</code> )          \u2013            <p>The fitted encoder.</p> </li> </ul>"},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder.get_feature_names_out","title":"<code>get_feature_names_out()</code>","text":"<p>Get the output feature names.</p>"},{"location":"API/encoding/TargetEncoder/#sklearo.encoding.TargetEncoder.transform","title":"<code>transform(X)</code>","text":"<p>Transform the data.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>The input data.</p> </li> </ul>"},{"location":"API/encoding/WOEEncoder/","title":"WOEEncoder","text":""},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder","title":"<code>sklearo.encoding.WOEEncoder(columns=(nw.Categorical, nw.String), underrepresented_categories='raise', fill_values_underrepresented=(-999.0, 999.0), unseen='raise', fill_value_unseen=0.0, missing_values='encode', cv=5)</code>","text":"<p>Weight of Evidence (WOE) Encoder with support for multiclass classification.</p> <p>This class provides functionality to encode categorical features using the Weight of Evidence (WOE) technique. WOE is commonly used in credit scoring and other binary classification problems to transform categorical variables into continuous variables, however it can easily be extended to all sort of classification problems, including multiclass classification.</p> <p>WOE is defined as the natural logarithm of the ratio of the distribution of events for a class over the distribution of non-events for that class.</p> <pre><code>WOE = ln((% of events) / (% of non events))\n</code></pre> <p>Some articles explain it as <code>ln((% of non events) / (% of events))</code>, but in this way the WOE will be inversely correlated to the target variable. In this implementation, the WOE is calculated as the first formula, making it directly correlated to the target variable. I personally think that it makes the interpretation of the WOE easier and it won't affect the performance of the model.</p> <p>So let's say that the event to predict is default on a loan (class 1) and the non-event is not defaulting on a loan (class 0). The WOE for a category is calculated as follows:</p> <pre><code>WOE = ln((% of defaults with the category) / (% of non-defaults in the category))\n    = ln(\n        (number of defaults from the category / total number of defaults) /\n        (number of non-defaults from the category / total number of non-defaults)\n      )\n</code></pre> <p>The WOE value defined like this will be positive if the category is more likely to be default (positive class) and negative if it is more likely to be repaid (positive class).</p> <p>The WOE encoding is useful for logistic regression and other linear models, as it transforms the categorical variables into continuous variables that can be used as input features.</p> Notes <p>Parameters:</p> <ul> <li> <code>columns</code>               (<code>(str, list[str], list[DTypes])</code>, default:                   <code>(Categorical, String)</code> )           \u2013            <p>list of columns to encode.</p> <ul> <li>If a list of strings is passed, it is treated as a list of column names to encode.</li> <li>If a single string is passed instead, it is treated as a regular expression pattern to     match column names.</li> <li>If a list of <code>narwhals.typing.DTypes</code>     is passed, it will select all columns matching the specified dtype.</li> </ul> <p>Defaults to <code>[narwhals.Categorical, narwhals.String]</code>, meaning that all categorical and string columns are selected by default.</p> </li> <li> <code>underrepresented_categories</code>               (<code>str</code>, default:                   <code>'raise'</code> )           \u2013            <p>Strategy to handle underrepresented categories. Underrepresented categories in this context are categories that are never associated with one of the target classes. In this case the WOE is undefined (mathematically it would be either -inf or inf).</p> <ul> <li>If <code>'raise'</code>, an error is raised when a category is underrepresented.</li> <li>If <code>'fill'</code>, the underrepresented categories are encoded using the     fill_values_underrepresented values.</li> </ul> </li> <li> <code>fill_values_underrepresented</code>               (<code>list[int, float, None]</code>, default:                   <code>(-999.0, 999.0)</code> )           \u2013            <p>Fill values to use for underrepresented categories. The first value is used when the category has no events (e.g. defaults) and the second value is used when the category has no non-events (e.g. non defaults). Only used when <code>underrepresented_categories='fill'</code>.</p> </li> <li> <code>unseen</code>               (<code>str</code>, default:                   <code>'raise'</code> )           \u2013            <p>Strategy to handle categories that appear during the <code>transform</code> step but where never encountered in the <code>fit</code> step.</p> <ul> <li>If <code>'raise'</code>, an error is raised when unseen categories are found.</li> <li>If <code>'ignore'</code>, the unseen categories are encoded with the fill_value_unseen.</li> </ul> </li> <li> <code>fill_value_unseen</code>               (<code>(int, float, None)</code>, default:                   <code>0.0</code> )           \u2013            <p>Fill value to use for unseen categories. Only used when <code>unseen='ignore'</code>.</p> </li> <li> <code>missing_values</code>               (<code>str</code>, default:                   <code>'encode'</code> )           \u2013            <p>Strategy to handle missing values.</p> <ul> <li>If <code>'encode'</code>, missing values are initially replaced with <code>'MISSING'</code> and the WOE is computed as if it were a regular category.</li> <li>If <code>'ignore'</code>, missing values are left as is.</li> <li>If <code>'raise'</code>, an error is raised when missing values are found.</li> </ul> </li> <li> <code>cv</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Number of cross-validation folds to use when calculating the WOE.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>columns_</code>               (<code>list[str]</code>)           \u2013            <p>List of columns to be encoded, learned during fit.</p> </li> <li> <code>encoding_map_</code>               (<code>dict[str, dict[str, float]]</code>)           \u2013            <p>Nested dictionary mapping columns to their WOE values for each class, learned during fit.</p> </li> <li> <code>feature_names_in_</code>               (<code>list[str]</code>)           \u2013            <p>List of feature names seen during fit.</p> </li> </ul> <p>Examples:</p> <pre><code>import pandas as pd\nfrom sklearo.encoding import WOEEncoder\ndata = {\n    \"category\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n    \"target\": [1, 0, 0, 1, 1, 0, 1, 1, 0],\n}\ndf = pd.DataFrame(data)\nencoder = WOEEncoder()\nencoder.fit(df[[\"category\"]], df[\"target\"])\nencoded = encoder.transform(df[[\"category\"]])\nprint(encoded)\n   category\n0 -0.916291\n1 -0.916291\n2 -0.916291\n3  0.470004\n4  0.470004\n5  0.470004\n6  0.470004\n7  0.470004\n8  0.470004\n</code></pre> <p>Initializes the WoEEncoder with the specified parameters.</p>"},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder--cross-fitting","title":"Cross-fitting \ud83c\udfcb\ufe0f\u200d\u2642\ufe0f","text":"<p>This implementation uses an internal cross-fitting strategy to calculate the WOE values for the <code>fit_transform</code> method. This means that calling <code>.fit(X, y).transform(X)</code> will not return the same result as calling <code>.fit_transform(X, y)</code>. When calling <code>.fit_transform(X, y)</code>, the dataset is initially split into k folds (configurable via the <code>cv</code> parameter) then for each fold the WOE values are calculated using the data from all other folds. Finally, the transformer is fitted on the entire dataset. This is done to prevent leakage of the target information into the training data. This idea has been taken from scikit-learn's implementation of TargetEncoder. The reader is encouraged to learn more about cross-fitting on the scikit-learn documentation.</p>"},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder.__sklearn_clone__","title":"<code>__sklearn_clone__()</code>","text":"<p>Clone the transformer.</p>"},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder.check_target_type","title":"<code>check_target_type(y)</code>","text":"<p>Check the type of the target variable.</p>"},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder.fit","title":"<code>fit(X, y)</code>","text":"<p>Fit the encoder.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>The input data.</p> </li> <li> <code>y</code>               (<code>Series</code>)           \u2013            <p>The target variable.</p> </li> </ul>"},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder.fit_transform","title":"<code>fit_transform(X, y)</code>","text":"<p>Fit the encoder and transform the dataframe using cross-fitting.</p> Notes <p>Due to the cross fitting nature of target encoding, the <code>fit_transform</code> method is NOT equivalent to calling <code>fit</code> followed by <code>transform</code>. Please refer to the note on cross fitting.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>The input data.</p> </li> <li> <code>y</code>               (<code>Series</code>)           \u2013            <p>The target variable.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseTargetEncoder</code> (              <code>BaseTargetEncoder</code> )          \u2013            <p>The fitted encoder.</p> </li> </ul>"},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder.get_feature_names_out","title":"<code>get_feature_names_out()</code>","text":"<p>Get the output feature names.</p>"},{"location":"API/encoding/WOEEncoder/#sklearo.encoding.WOEEncoder.transform","title":"<code>transform(X)</code>","text":"<p>Transform the data.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>The input data.</p> </li> </ul>"},{"location":"API/utils/infer_target_type/","title":"Infer target type","text":""},{"location":"API/utils/infer_target_type/#sklearo.utils.infer_target_type","title":"<code>sklearo.utils.infer_target_type(y)</code>","text":"<p>Infer the type of target variable based on the input series.</p> <p>This function determines the type of target variable based on the unique values and data type of the input series.</p> <p>Parameters:</p> <ul> <li> <code>y</code>               (<code>Series</code>)           \u2013            <p>The target variable series.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The inferred type of target variable, which can be one of the following:</p> <ul> <li><code>\"binary\"</code>: Returned when the target variable contains exactly two unique values and   is of an integer, boolean, string or categorical data type or it's floating point with   no decimal digits (e.g. <code>[0.0, 1.0]</code>).</li> <li><code>\"multiclass\"</code>: Returned when the target variable has more than two unique values and   is of an integer, boolean, string or categorical data type or it's floating point with   no decimal digits (e.g. <code>[0.0, 1.0, 2.0]</code>). In case of floating point data type, the   unique values should be consecutive integers.</li> <li><code>\"continuous\"</code>: Returned when the target variable is of a floating-point data type and   contains at least one non-integer value or the unique values are not consecutive   integers.</li> <li><code>\"unknown\"</code>: Returned when the input series is none of the above types.</li> </ul> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; infer_target_type(pd.Series([1, 2, 3])\n\"multiclass\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1, 2, 1])\n\"binary\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1, 2, 4])\n\"multiclass\"\n&gt;&gt;&gt; infer_target_type(pd.Series([\"a\", \"b\", \"c\"])\n\"multiclass\"\n&gt;&gt;&gt; infer_target_type(pd.Series([\"a\", \"b\", \"a\"])\n\"binary\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1.0, 2.0, 3.5])\n\"continuous\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1.0, 3.5, 3.5])\n\"continuous\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1.0, 2.0, 4.0])\n\"continuous\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1.0, 4.0, 4.0])\n\"binary\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1.0, 2.0, 3.0])\n\"multiclass\"\n&gt;&gt;&gt; infer_target_type(pd.Series([1.0, 2.0, 1.0])\n\"binary\"\n</code></pre>"}]}